{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a8e2cde1-8152-4fbb-b5af-6b925ff25c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file...\n",
      "Formatting content...\n",
      "Tokenizing words...\n",
      "Predicting Categories (this is going to be a while)...\n",
      "Calculating category probability: 1/41 - PARENTING\n",
      "Calculating category probability: 2/41 - TECH\n",
      "Calculating category probability: 3/41 - BUSINESS\n",
      "Calculating category probability: 4/41 - POLITICS\n",
      "Calculating category probability: 5/41 - FOOD & DRINK\n",
      "Calculating category probability: 6/41 - WELLNESS\n",
      "Calculating category probability: 7/41 - HEALTHY LIVING\n",
      "Calculating category probability: 8/41 - ENTERTAINMENT\n",
      "Calculating category probability: 9/41 - MEDIA\n",
      "Calculating category probability: 10/41 - FIFTY\n",
      "Calculating category probability: 11/41 - PARENTS\n",
      "Calculating category probability: 12/41 - STYLE\n",
      "Calculating category probability: 13/41 - COMEDY\n",
      "Calculating category probability: 14/41 - SPORTS\n",
      "Calculating category probability: 15/41 - STYLE & BEAUTY\n",
      "Calculating category probability: 16/41 - WORLDPOST\n",
      "Calculating category probability: 17/41 - TASTE\n",
      "Calculating category probability: 18/41 - BLACK VOICES\n",
      "Calculating category probability: 19/41 - WEIRD NEWS\n",
      "Calculating category probability: 20/41 - HOME & LIVING\n",
      "Calculating category probability: 21/41 - GOOD NEWS\n",
      "Calculating category probability: 22/41 - DIVORCE\n",
      "Calculating category probability: 23/41 - WOMEN\n",
      "Calculating category probability: 24/41 - QUEER VOICES\n",
      "Calculating category probability: 25/41 - THE WORLDPOST\n",
      "Calculating category probability: 26/41 - IMPACT\n",
      "Calculating category probability: 27/41 - TRAVEL\n",
      "Calculating category probability: 28/41 - SCIENCE\n",
      "Calculating category probability: 29/41 - RELIGION\n",
      "Calculating category probability: 30/41 - ARTS\n",
      "Calculating category probability: 31/41 - MONEY\n",
      "Calculating category probability: 32/41 - WORLD NEWS\n",
      "Calculating category probability: 33/41 - COLLEGE\n",
      "Calculating category probability: 34/41 - LATINO VOICES\n",
      "Calculating category probability: 35/41 - CULTURE & ARTS\n",
      "Calculating category probability: 36/41 - WEDDINGS\n",
      "Calculating category probability: 37/41 - CRIME\n",
      "Calculating category probability: 38/41 - GREEN\n",
      "Calculating category probability: 39/41 - EDUCATION\n",
      "Calculating category probability: 40/41 - ARTS & CULTURE\n",
      "Calculating category probability: 41/41 - ENVIRONMENT\n",
      "          category                                            content  \\\n",
      "0        PARENTING  [baby, name, weapon, mass, humiliation, whats,...   \n",
      "1             TECH  [content, brief, whats, hacking, facebook, app...   \n",
      "2         BUSINESS                 [companies, control, worlds, food]   \n",
      "3         POLITICS  [trump, inauguration, met, mass, march, washin...   \n",
      "4         POLITICS  [lot, people, looking, wake, trumps, election,...   \n",
      "5     FOOD & DRINK  [thanksgiving, stuffing, cookies, blow, mind, ...   \n",
      "6         WELLNESS  [dental, crisis, looms, californias, children,...   \n",
      "7   HEALTHY LIVING  [face, mental, health, patient, its, scary, li...   \n",
      "8    ENTERTAINMENT  [someone, tried, come, kim, kardashian, john, ...   \n",
      "9         POLITICS  [un, ban, words, challenge, bad, behavior, ame...   \n",
      "10        POLITICS  [obama, administration, disowns, pentagons, mi...   \n",
      "11           MEDIA  [climate, scientists, like, street, preachers,...   \n",
      "12        BUSINESS  [genetic, testing, adhere, medical, business, ...   \n",
      "13   ENTERTAINMENT  [political, america, mashup, perfect, election...   \n",
      "14           FIFTY  [notes, dive, bar, xi, heres, resume, male, ol...   \n",
      "15       PARENTING  [wish, started, running, new, mom, recently, s...   \n",
      "16         PARENTS  [talk, kids, ebola, without, scaring, sht, ebo...   \n",
      "17            TECH  [ipad, mini, retina, display, coming, year, ca...   \n",
      "18        WELLNESS  [countdown, fitness, goals, countdown, new, ye...   \n",
      "19        WELLNESS  [food, safety, proposal, meetings, launched, f...   \n",
      "20        POLITICS  [macarthur, foundation, spend, millions, thin,...   \n",
      "21        POLITICS  [stephen, colberts, show, rigged, hillary, cli...   \n",
      "22           STYLE  [prince, harry, meghan, markle, serious, relig...   \n",
      "23        WELLNESS  [bpa, linked, potential, heart, kidney, proble...   \n",
      "24        WELLNESS  [vaccines, linked, long, term, effects, kids, ...   \n",
      "25        WELLNESS  [breakfast, really, important, meal, day, main...   \n",
      "26          COMEDY  [things, know, comedians, its, easy, think, co...   \n",
      "27           STYLE  [carrie, underwood, posts, bikini, pic, import...   \n",
      "28   ENTERTAINMENT  [woman, refuses, leave, husband, threatened, k...   \n",
      "29            TECH  [state, wants, learn, according, google, autof...   \n",
      "30          SPORTS  [nfl, lobbyist, opens, door, new, position, da...   \n",
      "31       PARENTING  [cause, miscarriage, study, says, super, ferti...   \n",
      "32  STYLE & BEAUTY  [know, spring, fashion, world, mother, nature,...   \n",
      "33       WORLDPOST  [nato, turkey, fighting, terrorism, really, pr...   \n",
      "34  HEALTHY LIVING            [smoothie, bowl, probably, full, sugar]   \n",
      "35        WELLNESS  [salma, hayeks, total, body, workout, make, mo...   \n",
      "36        POLITICS  [huffpost, rise, morning, newsbrief, october, ...   \n",
      "37        POLITICS  [hillary, clintons, pot, proposal, popular, pr...   \n",
      "38        POLITICS  [america, privilege, really, buy, anything, am...   \n",
      "39  STYLE & BEAUTY  [pinterest, accounts, changing, see, style, ka...   \n",
      "40           TASTE     [singer, rick, astley, coming, beer, get, guy]   \n",
      "41         PARENTS  [farewell, note, daughters, preschool, teacher...   \n",
      "42            TECH  [internet, things, needs, code, ethics, often,...   \n",
      "43    BLACK VOICES  [tiffany, haddish, seriously, loves, bidets, h...   \n",
      "44        WELLNESS  [upsize, love, maybe, honest, wanted, wed, act...   \n",
      "45      WEIRD NEWS  [true, story, rooster, went, vegas, halloween,...   \n",
      "46   HOME & LIVING  [house, haunters, designers, specialize, haunt...   \n",
      "47           TASTE  [vancouvers, wildly, popular, dinner, series, ...   \n",
      "48          SPORTS  [litmus, test, iran, world, stage, sports, air...   \n",
      "49   ENTERTAINMENT  [strange, enchants, box, office, million, week...   \n",
      "\n",
      "   predicted_category  \n",
      "0         ENVIRONMENT  \n",
      "1         ENVIRONMENT  \n",
      "2         ENVIRONMENT  \n",
      "3         ENVIRONMENT  \n",
      "4         ENVIRONMENT  \n",
      "5         ENVIRONMENT  \n",
      "6         ENVIRONMENT  \n",
      "7         ENVIRONMENT  \n",
      "8         ENVIRONMENT  \n",
      "9         ENVIRONMENT  \n",
      "10        ENVIRONMENT  \n",
      "11        ENVIRONMENT  \n",
      "12        ENVIRONMENT  \n",
      "13        ENVIRONMENT  \n",
      "14              FIFTY  \n",
      "15        ENVIRONMENT  \n",
      "16        ENVIRONMENT  \n",
      "17        ENVIRONMENT  \n",
      "18        ENVIRONMENT  \n",
      "19        ENVIRONMENT  \n",
      "20        ENVIRONMENT  \n",
      "21        ENVIRONMENT  \n",
      "22        ENVIRONMENT  \n",
      "23        ENVIRONMENT  \n",
      "24        ENVIRONMENT  \n",
      "25        ENVIRONMENT  \n",
      "26        ENVIRONMENT  \n",
      "27        ENVIRONMENT  \n",
      "28        ENVIRONMENT  \n",
      "29        ENVIRONMENT  \n",
      "30        ENVIRONMENT  \n",
      "31        ENVIRONMENT  \n",
      "32        ENVIRONMENT  \n",
      "33          WORLDPOST  \n",
      "34        ENVIRONMENT  \n",
      "35        ENVIRONMENT  \n",
      "36        ENVIRONMENT  \n",
      "37        ENVIRONMENT  \n",
      "38        ENVIRONMENT  \n",
      "39        ENVIRONMENT  \n",
      "40              TASTE  \n",
      "41        ENVIRONMENT  \n",
      "42        ENVIRONMENT  \n",
      "43        ENVIRONMENT  \n",
      "44        ENVIRONMENT  \n",
      "45        ENVIRONMENT  \n",
      "46        ENVIRONMENT  \n",
      "47        ENVIRONMENT  \n",
      "48        ENVIRONMENT  \n",
      "49        ENVIRONMENT  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "# Read the JSON File as a DataFrame\n",
    "print(\"Loading file...\")\n",
    "f = pd.read_json('News_Category_Dataset_v2.json', lines=True)\n",
    "df = f.sample(frac=0.01)\n",
    "\n",
    "# Use of the NLTK package to \"clean\" data by removing stop-words, and then assess most common remaining words\n",
    "ENGLISH_RE = re.compile(r'[a-z]+')\n",
    "stop_words = stopwords.words(\"english\")\n",
    "stop_words.extend(['said'])  # Removal of the word \"said\", a common stop-word not in the stop word corpus\n",
    "\n",
    "# Concatenate the headline and short descriptions and then parse only the columns we care about\n",
    "print(\"Formatting content...\")\n",
    "df = df.assign(content=(df[\"headline\"] + \" \" + df[\"short_description\"]))\n",
    "df = df[[\"category\", \"content\"]]\n",
    "\n",
    "# Remove stop words, numbers, and punctuation.\n",
    "# Note: We have to be careful with em dash characters because they will join words when removed, so we handle those separately.\n",
    "df['content'] = df['content'].apply(lambda x: ' '.join([re.sub('[^a-z\\s]+', '', re.sub('[-]+', ' ', word.lower())) for word in x.split() if word.lower() not in stop_words and ENGLISH_RE.match(word.lower())]))\n",
    "\n",
    "# Tokenize words\n",
    "print(\"Tokenizing words...\")\n",
    "word_freq = df.groupby(['category'], as_index = False)['content'].apply(' '.join)\n",
    "word_freq['word'] = word_freq['content'].apply(lambda x: nltk.FreqDist(x.split(' ')).items())\n",
    "word_freq = word_freq.explode('word').reset_index(drop = True)\n",
    "word_freq['freq'] = word_freq.word.apply(lambda pair: pair[1])\n",
    "word_freq['word'] = word_freq.word.apply(lambda pair: pair[0])\n",
    "del word_freq['content']\n",
    "\n",
    "# Fill remaining words with zero values\n",
    "word_freq = word_freq.pivot(*word_freq).stack(dropna=False).fillna(0).reset_index(name='freq')\n",
    "\n",
    "# Laplacian Smoothing\n",
    "word_freq['freq'] += 1\n",
    "\n",
    "# Predict Categories for Articles\n",
    "def p_word_given_cat(category_filter, word):\n",
    "    word_filter = category_filter.loc[category_filter['word'] == word]\n",
    "    return word_filter.iloc[0]['p_given_cat']\n",
    "\n",
    "print(\"Predicting Categories (this is going to be a while)...\")\n",
    "df['content'] = df['content'].apply(lambda x: x.split())\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "category_totals = df.groupby('category').size()\n",
    "category_totals += 1\n",
    "word_freq['p_given_cat'] = word_freq.groupby('category')['freq'].transform(lambda x: x / category_totals[x.name])\n",
    "\n",
    "curr = 1\n",
    "categories = df['category'].unique()\n",
    "\n",
    "articles_expanded = df.explode('content')\n",
    "for category in categories:\n",
    "    print(\"Calculating category probability: \" + str(curr) + \"/\" + str(categories.size) + \" - \" + category)\n",
    "    category_filter = word_freq.loc[word_freq['category'] == category]\n",
    "    cat_articles = df.loc[df['category'] == category].shape[0]\n",
    "    p_cat = cat_articles / df.shape[0]\n",
    "    df[category] = df['content'].apply(lambda x: category_filter[category_filter['word'].isin(x)]['p_given_cat'].prod()) * p_cat\n",
    "    curr += 1\n",
    "\n",
    "df['predicted_category'] = df[df.columns.difference(['category', 'content'])].idxmax(axis=1)\n",
    "df = df.drop(df.columns.difference(['category', 'content', 'predicted_category']), axis=1).reset_index(drop = True)\n",
    "\n",
    "print(df.head(50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
